Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	create_confound_file
	1

[Thu May 21 14:31:29 2020]
rule create_confound_file:
    input: /Users/switt/Documents/ComputationalCore/NoleControl/fmriprep_1.3.2/fmriprep/sub-CT02/func/sub-CT02_task-rest_run-01_desc-confounds_regressors.tsv, /Users/switt/Documents/ComputationalCore/NoleControl/confounder_output_snakemake/confounds_dictionary.json
    output: /Users/switt/Documents/ComputationalCore/NoleControl/FEAT3/task-rest/sub-CT02/confound-noconfounds/run-01/confounds-noconfounds.txt
    log: /Users/switt/Documents/ComputationalCore/NoleControl/FEAT3/task-rest/sub-CT02/confound-noconfounds/run-01/confounds-noconfounds.log
    jobid: 0
    wildcards: task=rest, subject=CT02, confound_name=noconfounds, run=01

/Users/switt/anaconda3/envs/snakemake-tutorial/bin/python3.6 /Users/switt/Documents/GitHub/confounder-snakemake/.snakemake/scripts/tmpp3v2pk61.create_confound_files.py
[Thu May 21 14:31:30 2020]
Finished job 0.
1 of 1 steps (100%) done
Complete log: /Users/switt/Documents/GitHub/confounder-snakemake/.snakemake/log/2020-05-21T143128.877765.snakemake.log
